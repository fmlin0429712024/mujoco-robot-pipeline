# ğŸ¤– Trossen Arm Pick & Place with ACT Policy

> **My First Robot Project** - Learning robotics by building an end-to-end imitation learning pipeline

This project demonstrates a complete robotics learning pipeline using the **ACT (Action Chunking with Transformers)** policy from LeRobot to teach a simulated Trossen robot arm to pick up a cube and place it in a bucket.

## ğŸ“º Video Showcase

| Phase | Video | Description |
|-------|-------|-------------|
| **Phase 1** | [Expert Demo](https://youtu.be/VuP907sxELQ) | Scripted expert policy successfully picking and placing |
| **Phase 1** | [Random Policy](https://youtu.be/IaS8G5BYmAQ) | Untrained arm moving randomly (baseline) |
| **Phase 1** | [Before Training](https://youtu.be/tw9J1FFLFPs) | Arm at rest / minimal movement |
| **Phase 2** | [After Training (30k steps)](https://youtu.be/ULep7-XoTZM) | ACT policy attempting pick-and-place |

> ğŸ“ *Videos hosted on YouTube*

---

## ğŸ¯ Project Overview

### The 3-Phase Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PHASE 1       â”‚     â”‚   PHASE 2       â”‚     â”‚   PHASE 3       â”‚
â”‚  Data Collectionâ”‚â”€â”€â”€â”€â–¶â”‚    Training     â”‚â”€â”€â”€â”€â–¶â”‚   Deployment    â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚ â€¢ MuJoCo sim    â”‚     â”‚ â€¢ ACT policy    â”‚     â”‚ â€¢ Sim deploy    â”‚
â”‚ â€¢ 50 episodes   â”‚     â”‚ â€¢ 30k steps     â”‚     â”‚ â€¢ Evaluation    â”‚
â”‚ â€¢ Expert demos  â”‚     â”‚ â€¢ LeRobot       â”‚     â”‚ â€¢ Coming soon   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Learning Path: Zero to Production

**New to robot learning?** This project follows a structured 7-part journey, taking you from basic concepts to advanced cloud-scale architecture.

### **Phase 1: Build Your Worldview** (Theory)
*Understand why robots need learning and where the business value is.*

1. **[01 - Robot Learning Methods Overview](docs/01_robot_learning_methods_overview.md)**
   - When to use learning vs. classical methods (IL vs. RL vs. SLAM).
2. **[02 - Robotics Use Cases and Solutions](docs/02_robotics_use_cases_and_solutions.md)**
   - Real-world ROI: How an AMR fleet saves $2M/year.

### **Phase 2: Get Your Hands Dirty** (Practice)
*The core hands-on lab: Building an ACT Model Training Pipeline.*

3. **[05 - Demo Design Architecture](docs/05_demo_design_architecture.md)**
   - The architecture of our MuJoCo + LeRobot pipeline.
4. **Hands-On Lab: The ACT Pipeline**
   - **[Phase 1: Data Collection](docs/guides/phase1_data_collection.md)** (Record expert demos).
   - **[Phase 2: Training](docs/guides/phase2_training.md)** (Train the ACT Policy).
   - **[Phase 3: Deployment](docs/guides/phase3_deployment.md)** (Run the trained model).

### **Phase 3: Strategic Vision** (Advanced)
*Scale from a laptop demo to a global fleet of 2,000 robots.*

5. **[03 - Isaac Sim Platform Strategy](docs/03_isaac_sim_platform_strategy.md)**
   - The strategic roadmap: AMR â†’ ARM â†’ HUMANOID.
6. **[04 - MuJoCo vs Isaac Sim](docs/04_mujoco_vs_isaac_sim.md)**
   - Choosing the right simulator for the right phase.
7. **[06 - From Demo to Production](docs/06_from_demo_to_production.md)**
   - The "Practical Bridge": Edge deployment, safety layers, and calibration.
8. **[07 - Advanced Cloud Architecture](docs/07_advanced_cloud_architecture.md)**
   - The "Three-Computer" Vision (Jensen Huang).
   - Hybrid Cloud Orchestration & Data Flywheels.

---

## ğŸ¯ Quick Start Choices

**1. Just want to see it work?**
```bash
# Watch the expert policy in action (no training needed)
python scripts/visualize_expert_demo.py
# Then open: visualizations/expert_demo.mp4
```

**2. Ready to learn?**
Start with **[Doc 01](docs/01_robot_learning_methods_overview.md)**.

**3. Planning a product?**
Jump to **[Doc 06](docs/06_from_demo_to_production.md)** or **[Doc 07](docs/07_advanced_cloud_architecture.md)**.

---

> ğŸ“ **For Developers:** [Doc 05](docs/05_demo_design_architecture.md) explains the code architecture in 5 minutes.


---

## ğŸ“ Project Structure

```
trossen-pick-place/
â”œâ”€â”€ trossen_arm_mujoco/          # MuJoCo simulation environment
â”‚   â”œâ”€â”€ assets/                  # Robot MJCF models
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ record_sim_episodes.py  # Phase 1: Data collection
â”‚   â”œâ”€â”€ sim_env.py               # Joint-space environment
â”‚   â”œâ”€â”€ ee_sim_env.py            # End-effector environment
â”‚   â”œâ”€â”€ scripted_policy.py       # Expert pick-and-place policy
â”‚   â””â”€â”€ gym_env.py               # Gymnasium wrapper for LeRobot
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_lerobot_dataset.py   # Convert HDF5 â†’ LeRobot format
â”‚   â”œâ”€â”€ train_policy.py             # Phase 2: ACT training
â”‚   â”œâ”€â”€ eval_policy.py              # Evaluate trained policy
â”‚   â”œâ”€â”€ visualize_expert_demo.py    # Generate expert video
â”‚   â”œâ”€â”€ visualize_random_policy.py  # Generate random baseline video
â”‚   â””â”€â”€ visualize_untrained_policy.py  # Generate untrained video
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Raw HDF5 episode recordings
â”‚   â””â”€â”€ lerobot/                 # LeRobot dataset format
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ train/act_pick_place_30k/  # Trained model checkpoints
â”œâ”€â”€ visualizations/              # Generated demo videos
â”‚   â”œâ”€â”€ expert_demo.mp4
â”‚   â”œâ”€â”€ random_policy.mp4
â”‚   â”œâ”€â”€ untrained_policy.mp4
â”‚   â””â”€â”€ after_training.mp4
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### Step-by-Step Guides

Follow these guides to reproduce the complete learning pipeline:

1. **[Phase 1: Data Collection](docs/phase1_data_collection.md)** (~25 min)
   - Record 50 expert demonstrations
   - Convert to LeRobot format
   - Generate expert demo video

2. **[Phase 2: Training](docs/phase2_training.md)** (~2-3 hours)
   - Generate baseline videos (random & untrained)
   - Train ACT policy for 30k steps
   - Monitor training progress

3. **[Phase 3: Deployment](docs/phase3_deployment.md)** (~10 min)
   - Run trained policy in simulation
   - Record deployment video
   - Compare results

4. **[Cleanup](docs/cleanup.md)** (~2 min)
   - Free ~29GB disk space
   - Keep only essential files

### Prerequisites

```bash
# Python 3.10+
pip install lerobot mujoco dm_control h5py opencv-python
```

### One-Line Quick Test

```bash
# See the expert policy in action (no training required)
python scripts/visualize_expert_demo.py && open visualizations/expert_demo.mp4
```
*Coming soon...*

---

## ğŸ“Š Training Results

| Metric | Value |
|--------|-------|
| Training Steps | 30,000 |
| Episodes | 50 |
| Batch Size | 8 |
| Final Loss | 0.036 |
| Device | Apple M-series (MPS) |

### Loss Progression

```
Step     Loss     Notes
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0k       4.374    Initial
5k       0.073    Rapid drop
10k      0.057    Checkpoint 1
20k      0.043    Continued improvement
30k      0.036    Final model
```

---

## ğŸ“ What I Learned

### Phase 1: Data Collection
- Recording expert demonstrations in simulation
- Importance of action representation (action[t] = target position, not current)
- HDF5 data storage for robot trajectories

### Phase 2: Training
- ACT (Action Chunking with Transformers) architecture
- LeRobot dataset format and video encoding
- Training on Apple Silicon (MPS device)
- ImageNet normalization for vision models

### Phase 3: Deployment (Upcoming)
- Sim-to-real transfer challenges
- Real-world latency and noise handling
- Safety constraints for physical robots

---

## ğŸ› ï¸ Key Files Explained

| File | Purpose |
|------|---------|
| `scripted_policy.py` | Expert policy using inverse kinematics |
| `record_sim_episodes.py` | Records expert demos to HDF5 |
| `create_lerobot_dataset.py` | Converts HDF5 â†’ LeRobot Parquet + video |
| `train_policy.py` | Launches ACT training with LeRobot |
| `eval_policy.py` | Evaluates trained policy with video output |
| `gym_env.py` | Gymnasium wrapper for LeRobot compatibility |

---

## ğŸ“š References

- [LeRobot](https://github.com/huggingface/lerobot) - Hugging Face robotics library
- [ACT Policy](https://arxiv.org/abs/2304.13705) - Action Chunking with Transformers
- [Trossen Robotics](https://www.trossenrobotics.com/) - Robot arm hardware

---

## ğŸ“ License

MIT License - Feel free to use this for learning!

---

*This is my first robot project. Feedback and suggestions welcome! ğŸ¤–*
